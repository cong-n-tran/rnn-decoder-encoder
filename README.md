# Text Reversal Detection with Decoder Encoder Recurrent Neural Networks

This repository implements encoder-decoder recurrent neural networks and Transformer models to determine whether a sentence is reversed or not. The models are trained on a dataset of reversed and non-reversed text sequences.

**Features:**
- Data preprocessing and vectorization for normal and reversed text
- Encoder-decoder architecture using LSTM layers
- Transformer models with positional embeddings and multi-head attention
- Training and validation utilities for the reversal detection task
- Inference functions for classifying new text sequences

These models demonstrate how sequence-to-sequence architectures can learn to identify text reversal patterns through positional information and sequential dependencies.
